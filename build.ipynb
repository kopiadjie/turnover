{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load sumberdaya dan pendefinisian fungsi preprocessing untuk dataset model pelatihan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LINK REFERENSI\n",
    "* stopwords : https://github.com/stopwords-iso/stopwords-id/blob/master/stopwords-id.txt\n",
    "* kamus leksikon : https://github.com/onpilot/sentimen-bahasa/tree/master\n",
    "* kamus bahasa indonesia : https://github.com/damzaky/kumpulan-kata-bahasa-indonesia-KBBI/blob/master/list_1.0.0.txt\n",
    "* kamus slang : https://github.com/nasalsabila/kamus-alay/blob/master/colloquial-indonesian-lexicon.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def load_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return set(file.read().splitlines())\n",
    "    \n",
    "def load_lexicon(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return set(json.load(file))  \n",
    "    \n",
    "slang_dict = json.load(open(\"txt/kamusSlang.json\", \"r\", encoding=\"utf-8\"))\n",
    "stopwords = load_file('txt/stopwords-1.txt')\n",
    "kamus_indonesia = load_file('txt/kamusIndonesia.txt')\n",
    "pos_lexicon = load_lexicon('leksikon/leksikon-pos.json')\n",
    "neg_lexicon = load_lexicon('leksikon/leksikon-neg.json')\n",
    "\n",
    "def preprocessing(text, slang_dict, stopwords, kamus_indonesia, stemmer):\n",
    "    text = text.lower()  # Case folding\n",
    "    text = re.sub(r\"\\\\t|\\\\n|\\\\u|\\\\|http[s]?://\\\\S+|[@#][A-Za-z0-9_]+\", \" \", text)  # Menghapus karakter khusus\n",
    "    text = re.sub(r\"\\\\d+\", \"\", text)  # Menghapus angka\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # Menghapus tanda baca (pakai import string)\n",
    "    text = re.sub(r\"\\\\s+\", ' ', text).strip()  # merapihkan spasi ganda\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text) # Menghapus satu huruf (besar/kecil)\n",
    "    text = ' '.join([slang_dict.get(word, word) for word in text.split()]) # Normalisasi (pemanfaatan kamus slang)\n",
    "    text = word_tokenize(text) # Tokenisasi (sebelum stemming)\n",
    "    text = [stemmer.stem(word) for word in text] # Stemming\n",
    "    text = [word for word in text if word not in stopwords and len(word) > 3 and word in kamus_indonesia] # Stopwords & memilah kata\n",
    "    text = ' '.join(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fungsi pelabelan sentimen (boleh diskip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hitung_sentimen(text, leksikon_positif, leksikon_negatif, prior_positif=0.5, prior_negatif=0.5):\n",
    "    # skor total\n",
    "    total_skor_positif = 0\n",
    "    total_skor_negatif = 0\n",
    "\n",
    "    # algoritma iterasi seluruh kata pada kalimat\n",
    "    for kata in text.split():\n",
    "        # perhitungan P(kata|positif) dan P(kata|negatif) dalam kamus jika ditemukan.\n",
    "        probabilitas_kata_positif = 1 / len(leksikon_positif) if kata in leksikon_positif else 0\n",
    "        probabilitas_kata_negatif = 1 / len(leksikon_negatif) if kata in leksikon_negatif else 0\n",
    "\n",
    "        # jumlah skor kata yang ditemukan dalam kamus\n",
    "        total_skor_kata = probabilitas_kata_positif + probabilitas_kata_negatif\n",
    "\n",
    "        # perhitungan skor sentimen positif dan negatif untuk kata\n",
    "        skor_sentimen_positif = probabilitas_kata_positif / total_skor_kata if total_skor_kata > 0 else 0\n",
    "        skor_sentimen_negatif = probabilitas_kata_negatif / total_skor_kata if total_skor_kata > 0 else 0\n",
    "\n",
    "        # penjumlahan skor positif dan negatif\n",
    "        total_skor_positif += skor_sentimen_positif\n",
    "        total_skor_negatif += skor_sentimen_negatif\n",
    "\n",
    "    # menghitung total skor semua kata pada kalimat\n",
    "    total_skor_semua = total_skor_positif + total_skor_negatif\n",
    "\n",
    "    # menghitung probabilitas untuk sentimen positif dan negatif pada kalimat\n",
    "    probabilitas_positif = ((total_skor_positif / total_skor_semua) * prior_positif) if total_skor_semua > 0 else 0\n",
    "    probabilitas_negatif = ((total_skor_negatif / total_skor_semua) * prior_negatif) if total_skor_semua > 0 else 0\n",
    "\n",
    "    # menentukan sentimen berdasarkan probabilitas sentimen tertinggi\n",
    "    if probabilitas_positif > probabilitas_negatif:\n",
    "        return 'Positif', 1\n",
    "    elif probabilitas_negatif > probabilitas_positif:\n",
    "        return 'Negatif', -1\n",
    "    else:\n",
    "        return 'Netral', 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pemanggilan fungsi preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('code_filter_crawling/crawling.csv')\n",
    "df.rename(columns={\"full_text\" : \"teks\"}, inplace=True)\n",
    "df['teks'] = df['teks'].apply(lambda x: preprocessing(x, slang_dict, stopwords, kamus_indonesia,stemmer))\n",
    "\n",
    "df.to_csv('preprocessing/preprocessing.csv', index=False)\n",
    "df = df[df['teks'].str.strip().astype(bool)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pemanggilan fungsi pelabelan (boleh di skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['label' ,'skor']] = df['teks'].apply(lambda x: pd.Series(hitung_sentimen(x, pos_lexicon, neg_lexicon)))\n",
    "df = df[df['teks'].str.strip().astype(bool)]\n",
    "df.to_csv('dataset_berlabel/dataset_berlabel.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pengecekkan oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "df = pd.read_csv('dataset_berlabel/dataset_berlabel.csv')\n",
    "\n",
    "# 1. Hitung distribusi label\n",
    "label_distribution = Counter(df['label'])\n",
    "print(\"Distribusi Label:\", label_distribution)\n",
    "\n",
    "# 2. Periksa ketidakseimbangan\n",
    "is_balanced = len(set(label_distribution.values())) == 1\n",
    "if is_balanced:\n",
    "    print(\"Dataset sudah seimbang. Tidak perlu oversampling.\")\n",
    "else:\n",
    "    print(\"Dataset tidak seimbang. Oversampling dapat dipertimbangkan dengan menggunakan SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "df = df[['teks', 'label']]\n",
    "sns.countplot(data=df, x='label', color='green')\n",
    "plt.title('Distribusi Label')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Jumlah label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pelatihan model logistic regression (tanpa SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "data = pd.read_csv('dataset_berlabel/dataset_berlabel.csv')\n",
    "\n",
    "X = data['teks']\n",
    "y = data['label']\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# vektorisasi\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# melatih model Logistic Regression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# memprediksi hasil untuk data training dan testing\n",
    "y_train_pred = model.predict(X_train_tfidf)\n",
    "y_test_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# evaluasi model pada data training & testing\n",
    "print(\"Akurasi Traning:\", accuracy_score(y_train, y_train_pred))\n",
    "print(\"Akurasi Testing:\", accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# classification report untuk data testing\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Menghitung presisi, recall, dan F1-score secara keseluruhan\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "\n",
    "print(f\"Presisi (keseluruhan): {precision:.2f}\")\n",
    "print(f\"Recall (keseluruhan): {recall:.2f}\")\n",
    "print(f\"F1-Score (keseluruhan): {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pelatihan model logistic regression (menggunakan SMOTE) proporsi split data 70:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv('dataset_berlabel/dataset_berlabel.csv')\n",
    "X = df['teks']\n",
    "y = df['label']\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# vektorisasi\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# melatih model Logistic Regression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# memprediksi hasil data training dan testing\n",
    "y_train_pred = model.predict(X_train_smote)\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# evaluasi model training & testing\n",
    "print(\"Akurasi Training:\", accuracy_score(y_train_smote, y_train_pred))\n",
    "print(\"Akurasi Testing:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# classification untuk data testing\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# # Simpan model dan vectorizer\n",
    "# joblib.dump(model, \"model/model_sentimen.pkl\")\n",
    "# joblib.dump(vectorizer, \"model/vectorizer_sentimen.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Menghitung presisi, recall, dan F1-score secara keseluruhan\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Presisi (keseluruhan): {precision:.2f}\")\n",
    "print(f\"Recall (keseluruhan): {recall:.2f}\")\n",
    "print(f\"F1-Score (keseluruhan): {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "# fungsi menghitung confusion matrix\n",
    "cmtrain = confusion_matrix(y_train_smote, y_train_pred)\n",
    "cmtest = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# fungsi menampilkan confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cmtrain, display_labels=model.classes_)\n",
    "disp.plot(cmap=\"Greens\")\n",
    "plt.xlabel(\"Label Prediksi\")\n",
    "plt.ylabel(\"Label Aktual\")\n",
    "plt.title(\"Confusion Matrix Data Training\")\n",
    "plt.show()\n",
    "\n",
    "# fungsi menampilkan confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cmtest, display_labels=model.classes_)\n",
    "disp.plot(cmap=\"Greens\")\n",
    "plt.xlabel(\"Label Prediksi\")\n",
    "plt.ylabel(\"Label Aktual\")\n",
    "plt.title(\"Confusion Matrix Data Testing\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from sklearn.naive_bayes import MultinomialNB  # Ganti LogisticRegression dengan Naive Bayes\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# import joblib\n",
    "\n",
    "# # Baca dataset\n",
    "# df = pd.read_csv('dataset_berlabel/dataset_berlabel.csv')\n",
    "# X = df['teks']\n",
    "# y = df['label']\n",
    "\n",
    "# # Bagi data menjadi training dan testing\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# # Vectorisasi teks menggunakan TF-IDF\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "# X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# # Lakukan SMOTE untuk menangani data tidak seimbang\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_smote, y_train_smote = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# # Latih model Naive Bayes (Multinomial Naive Bayes)\n",
    "# model = MultinomialNB()  # Ganti LogisticRegression dengan Naive Bayes\n",
    "# model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# # Prediksi pada data training (untuk menghitung akurasi training)\n",
    "# y_train_pred = model.predict(X_train_smote)\n",
    "\n",
    "# # Prediksi pada data testing\n",
    "# y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# # Simpan model dan vectorizer\n",
    "# joblib.dump(model, \"model/model_sentimen.pkl\")\n",
    "# joblib.dump(vectorizer, \"model/vectorizer_sentimen.pkl\")\n",
    "\n",
    "# # Evaluasi model\n",
    "# print(\"Akurasi Training:\", accuracy_score(y_train_smote, y_train_pred))\n",
    "# print(\"Akurasi Testing:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
