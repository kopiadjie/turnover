{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta optimal: [-5.97303274  1.7764563 ]\n",
      "History biaya: [np.float64(0.21097826037977715), np.float64(0.2108616648304053), np.float64(0.21074523694405634), np.float64(0.21062897632622063), np.float64(0.21051288258364279), np.float64(0.21039695532431688), np.float64(0.21028119415748178), np.float64(0.21016559869361556), np.float64(0.2100501685444313), np.float64(0.20993490332287176)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Fungsi sigmoid\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Fungsi untuk menghitung nilai cost dengan gradient descent\n",
    "def compute_cost(X, y, theta):\n",
    "    m = len(y)  # Jumlah data pelatihan\n",
    "    z = np.dot(X, theta)  # Menghitung nilai z = X * theta\n",
    "    h = sigmoid(z)  # Menghitung probabilitas prediksi h = sigmoid(z)\n",
    "\n",
    "    # Fungsi cost\n",
    "    cost = - (1 / m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "    return cost\n",
    "\n",
    "# Fungsi untuk melakukan gradient descent\n",
    "def gradient_descent(X, y, theta, learning_rate, iterations):\n",
    "    m = len(y)  # Jumlah data pelatihan\n",
    "    cost_history = []  # Menyimpan sejarah biaya (cost)\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        z = np.dot(X, theta)  # Menghitung nilai z\n",
    "        h = sigmoid(z)  # Menghitung probabilitas prediksi h = sigmoid(z)\n",
    "        \n",
    "        # Menghitung gradien\n",
    "        gradient = (1 / m) * np.dot(X.T, (h - y))\n",
    "        \n",
    "        # Memperbarui theta\n",
    "        theta -= learning_rate * gradient\n",
    "        \n",
    "        # Menyimpan cost setelah setiap iterasi\n",
    "        cost_history.append(compute_cost(X, y, theta))\n",
    "    \n",
    "    return theta, cost_history\n",
    "\n",
    "# Inisialisasi data X (fitur) dan y (label sebenarnya)\n",
    "# Contoh data\n",
    "X = np.array([[1, 2], [1, 3], [1, 4], [1, 5]])  # X adalah matriks fitur (termasuk bias 1 pada kolom pertama)\n",
    "y = np.array([0, 0, 1, 1])  # y adalah label sebenarnya\n",
    "\n",
    "# Inisialisasi parameter theta (parameter model)\n",
    "theta = np.zeros(X.shape[1])\n",
    "\n",
    "# Parameter untuk gradient descent\n",
    "learning_rate = 0.1\n",
    "iterations = 1000\n",
    "\n",
    "# Melakukan gradient descent untuk mendapatkan theta optimal\n",
    "theta_optimal, cost_history = gradient_descent(X, y, theta, learning_rate, iterations)\n",
    "\n",
    "# Menampilkan hasil\n",
    "print(\"Theta optimal:\", theta_optimal)\n",
    "print(\"History biaya:\", cost_history[-10:])  # Menampilkan biaya terakhir untuk melihat konvergensi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi model: 33.33%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.1, iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.theta = None\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def compute_cost(self, X, y):\n",
    "        m = len(y)\n",
    "        z = np.dot(X, self.theta)\n",
    "        h = self.sigmoid(z)\n",
    "        cost = - (1 / m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "        return cost\n",
    "    \n",
    "    def gradient_descent(self, X, y):\n",
    "        m = len(y)\n",
    "        cost_history = []\n",
    "        \n",
    "        for _ in range(self.iterations):\n",
    "            z = np.dot(X, self.theta)\n",
    "            h = self.sigmoid(z)\n",
    "            gradient = (1 / m) * np.dot(X.T, (h - y))\n",
    "            self.theta -= self.learning_rate * gradient\n",
    "            cost_history.append(self.compute_cost(X, y))\n",
    "        \n",
    "        return cost_history\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = np.c_[np.ones((X.shape[0], 1)), X]  # Menambahkan kolom 1 untuk bias\n",
    "        self.theta = np.zeros(X.shape[1])  # Inisialisasi parameter theta\n",
    "        cost_history = self.gradient_descent(X, y)\n",
    "        return cost_history\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.c_[np.ones((X.shape[0], 1)), X]  # Menambahkan kolom 1 untuk bias\n",
    "        z = np.dot(X, self.theta)\n",
    "        h = self.sigmoid(z)\n",
    "        return (h >= 0.5).astype(int)\n",
    "\n",
    "# Contoh penggunaan dengan data teks\n",
    "if __name__ == \"__main__\":\n",
    "    # Contoh data teks dan label sentimen (0 = negatif, 1 = positif)\n",
    "    texts = [\n",
    "        \"rekan kerja tidak baik\", \"gaji terlalu sedikit untuk kebutuhan hidup di kota ini\" \n",
    "    ]\n",
    "    labels = np.array([1, 0, 1, 0, 1, 0, 1])\n",
    "\n",
    "    # Mengonversi teks menjadi vektor menggunakan TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(texts).toarray()  # Mengubah teks menjadi matriks fitur\n",
    "\n",
    "    # Membagi data menjadi set pelatihan dan pengujian\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Membuat objek model regresi logistik\n",
    "    model = LogisticRegression(learning_rate=0.1, iterations=1000)\n",
    "    \n",
    "    # Melatih model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Melakukan prediksi pada data pengujian\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Menghitung akurasi\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"Akurasi model: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitur (Kata-kata):\n",
      "['alas' 'alasan' 'cuman' 'gaji' 'karena' 'kecil' 'kerja' 'klasik' 'pindah']\n",
      "\n",
      "Vektor TF-IDF:\n",
      "[[0.         0.42567716 0.         0.30287281 0.42567716 0.42567716\n",
      "  0.30287281 0.42567716 0.30287281]\n",
      " [0.39054766 0.         0.39054766 0.27787788 0.         0.\n",
      "  0.55575576 0.         0.55575576]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Data input (teks latih)\n",
    "texts = [\n",
    "    \"Alasan klasik pindah kerja karena gaji kecil\",\n",
    "    \"Kerja pindah alas pindah kerja cuman gaji\"\n",
    "]\n",
    "\n",
    "# Membuat objek TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Melakukan vektorisasi TF-IDF pada teks\n",
    "tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Menampilkan hasil vektorisasi\n",
    "print(\"Fitur (Kata-kata):\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"\\nVektor TF-IDF:\")\n",
    "print(tfidf_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
